# Decision-Trees-and-Random-Forests
1.Train a Decision Tree Classifier and visualize the tree.

2.Analyze overfitting and control tree depth.

3.Train a Random Forest and compare accuracy.

4.Interpret feature importances.

5.Evaluate using cross-validation  


#  Objective: Learn tree-based models for classification & regression.
#  Tools: Scikit-learn, Graphviz

#  What Are Feature Importances?
In Random Forests, feature importance tells you how valuable each feature is in predicting the target. It's calculated based on how much each feature decreases the impurity (Gini or entropy) across all trees in the forest.


ðŸ”Ž Interpretation: Features like chest pain type (cp), maximum heart rate (thalach), and number of vessels (ca) carry strong predictive power for diagnosing heart disease.

